# HiveåŸºç¡€

## ä½“ç³»æ¶æ„

![img](./assets/0082zybpgy1gc1t0c9s7gj31hc0u0tfp.jpg)

### å®‰è£…å’Œé…ç½®Hive

æ ¸å¿ƒé…ç½®æ–‡ä»¶: `conf/hive-site.xml`

#### åµŒå…¥æ¨¡å¼: ä¸ä½¿ç”¨MySQLï¼Œä½¿ç”¨`Derby`æ•°æ®åº“å­˜å‚¨`Hive`å…ƒä¿¡æ¯

* å…ƒæ•°æ®ä¿¡æ¯å­˜å‚¨åœ¨å†…ç½®çš„`Derby`æ•°æ®åº“ä¸­
* åªè¿è¡Œå»ºç«‹ä¸€ä¸ªè¿æ¥
* è®¾ç½®`Hive`çš„ç¯å¢ƒå˜é‡
* è®¾ç½®ä¸€ä¸‹å‚æ•°

```xml
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:derby:;databaseName=metastore_db;create=true</value>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>org.apache.derby.jdbc.EmbeddedDriver</value>
  </property>
  <property>
    <name>hive.metastore.local</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.metastore.warehouse.dir</name>
    <!-- å¿…é¡»ä½¿ç”¨file://å¼€å¤´ï¼Œå¦åˆ™ä¼šé…ç½®åˆ°HDFSä¸Š -->
    <value>file:///Users/thomas/software/hive/apache-hive-2.3.2-bin/warehouse</value>
  </property>
</configuration>
```

```bash
# åˆå§‹åŒ–è„šæœ¬
schematool -dbType derby -initSchema 

# ä½¿ç”¨hive
hive

# ä½¿ç”¨é™é»˜æ¨¡å¼å¯åŠ¨hive
hive -S
```

<!-- more -->

#### æœ¬åœ°æ¨¡å¼|è¿œç¨‹æ¨¡å¼ï¼šä½¿ç”¨MySQL

```xml
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://127.0.0.1:3307/hive?useSSL=false</value>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <!-- <value>com.mysql.jdbc.Driver</value> -->
    <value>com.mysql.cj.jdbc.Driver</value>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>CN6ZRyjYb6bx6ZCq</value>
  </property>
</configuration>
```



```bash
# æ–°å»ºæ•°æ®åº“
# æ–°å»ºä¸€ä¸ªhiveçš„æ•°æ®åº“ï¼Œå¹¶ä¸”ä¿è¯hiveç”¨æˆ·æœ‰æƒé™è®¿é—®

# åˆå§‹æ•°æ®åº“
schematool -dbType mysql -initSchema 

# éœ€è¦å°†mysqlé©±åŠ¨ç¨‹åºå¤åˆ¶åˆ°libç›®å½•ä¸‹
org.apache.hadoop.hive.metastore.HiveMetaException: Failed to load driver
Underlying cause: java.lang.ClassNotFoundException : org.mysql.jdbc.Driver
Use --verbose for detailed stacktrace.
*** schemaTool failed ***

# åˆå§‹åŒ–æˆåŠŸ
omatically registered via the SPI and manual loading of the driver class is generally unnecessary.
Starting metastore schema initialization to 2.3.0
Initialization script hive-schema-2.3.0.mysql.sql
Initialization script completed
schemaTool completed

```

æ•°æ®åº“è¡¨çš„å…ƒä¿¡æ¯ä¿å­˜åœ¨TBLSé‡Œé¢

## æ•°æ®æ¨¡å‹

### å†…éƒ¨è¡¨

```sql
-- åˆ›å»ºæ•°æ®åº“è¡¨ï¼Œå¹¶æŒ‡å®šåˆ†éš”ç¬¦ 
create table emp
(
  empno int,
  ename string,
  job string,
  mgr int,
  hiredate string,
  sal int,
  comm int,
  deptno int
) 
-- æŒ‡å®šåˆ†éš”ç¬¦
row format delimited fields terminated by ',';

-- åˆ é™¤æ•°æ®åº“
drop table emp;

-- å¯¼å…¥HDFSæ•°æ®ï¼ˆä¼šåˆ é™¤åŸæ¥çš„æ–‡ä»¶ï¼‰
load data inpath '/scott/emp.csv' into table emp;

-- å¯¼å…¥æœ¬åœ°æ•°æ®
load data local inpath '/Users/thomas/Desktop/emp.csv' into table emp;

```

### åˆ†åŒºè¡¨ï¼šæé«˜æ€§èƒ½

```sql
-- åˆ›å»ºæ•°æ®åº“è¡¨ï¼ŒæŒ‡å®šåˆ†åŒºï¼Œå¹¶æŒ‡å®šåˆ†éš”ç¬¦
create table emp_part
(
  empno int,
  ename string,
  job string,
  mgr int,
  hiredate string,
  sal int,
  comm int
) 
-- æŒ‡å®šåˆ†åŒº
partitioned by (deptno int)
-- æŒ‡å®šåˆ†éš”ç¬¦
row format delimited fields terminated by ',';

-- æ’å…¥åˆ†åŒºæ•°æ®
insert into table emp_part partition(deptno=10) select empno,ename,job,mgr,hiredate,sal,comm from emp where deptno=10;
insert into table emp_part partition(deptno=20) select empno,ename,job,mgr,hiredate,sal,comm from emp where deptno=20;
insert into table emp_part partition(deptno=30) select empno,ename,job,mgr,hiredate,sal,comm from emp where deptno=30;
```

æŸ¥çœ‹æ‰§è¡Œè®¡åˆ’

```bash
# æ²¡ç”¨åˆ†åŒºè¡¨çš„æŸ¥è¯¢
hive> explain select * from emp where deptno = 10;
OK
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp
          Statistics: Num rows: 1 Data size: 629 Basic stats: COMPLETE Column stats: NONE
          Filter Operator
            predicate: (deptno = 10) (type: boolean)
            Statistics: Num rows: 1 Data size: 629 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: empno (type: int), ename (type: string), job (type: string), mgr (type: int), hiredate (type: string), sal (type: int), comm (type: int), 10 (type: int)
              outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
              Statistics: Num rows: 1 Data size: 629 Basic stats: COMPLETE Column stats: NONE
              ListSink

Time taken: 0.121 seconds, Fetched: 20 row(s)
hive> 

# ä½¿ç”¨äº†åˆ†åŒºè¡¨çš„æŸ¥è¯¢
hive> explain select * from emp_part where deptno = 10;
OK
STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp_part
          Statistics: Num rows: 3 Data size: 118 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: empno (type: int), ename (type: string), job (type: string), mgr (type: int), hiredate (type: string), sal (type: int), comm (type: int), 10 (type: int)
            outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
            Statistics: Num rows: 3 Data size: 118 Basic stats: COMPLETE Column stats: NONE
            ListSink

Time taken: 0.614 seconds, Fetched: 17 row(s)

# åˆ†åŒºè¡¨çš„æ•°æ®é‡(Data size)æ˜æ˜¾å°‘
```

### å¤–éƒ¨è¡¨

ç›´æ¥ä½¿ç”¨å¤–éƒ¨æ–‡ä»¶ï¼Œå¾ˆæ–¹ä¾¿åˆ›å»ºè¡¨ï¼Œä¸éœ€è¦å¯¼å…¥æ•°æ®

```sql
-- åˆ›å»ºå¤–éƒ¨è¡¨
create external table ext_student
(
  sid int,
  sname string,
  age int
)
row format delimited fields terminated by ','
location '/scott/student.csv';

-- æŸ¥è¯¢å¤–éƒ¨è¡¨æ•°æ®
hive> select * from ext_student;
OK
1	Tom	23
2	Mary	26
3	Mike	24
4	å°ç‹	28
5	ğŸ˜ğŸ¶	29
Time taken: 0.119 seconds, Fetched: 5 row(s)
hive> 
```

### æ¡¶è¡¨ï¼šç±»ä¼¼Hashåˆ†åŒº

```sql

create table emp_bucket
(
  empno int,
  ename string,
  job string,
  mgr int,
  hiredate string,
  sal int,
  comm int,
  deptno int
) clustered by (job) into 4 buckets
row format delimited fields terminated by ',';

-- æ’å…¥æ•°æ®
insert into table emp_bucket select * from emp;
```

### è§†å›¾ï¼šæ˜¯ä¸€ä¸ªè™šè¡¨

ç®€åŒ–å¤æ‚çš„æŸ¥è¯¢

```sql
-- åˆ›å»ºè§†å›¾
create view view_10 as select * from emp where deptno = 10;
```

## HiveæŸ¥è¯¢

```sql
-- åˆ›å»ºéƒ¨é—¨è¡¨
create external table dept
(
  deptno int,
  dname string,
  loc int
)
row format delimited fields terminated by ','
location '/scott/dept.csv';

drop table dept;

-- æŸ¥è¯¢æ‰€æœ‰å‘˜å·¥ä¿¡æ¯
select * from emp;

-- æŸ¥è¯¢å‘˜å·¥ä¿¡æ¯ï¼šå‘˜å·¥å·ï¼Œå§“åï¼Œæœˆè–ªï¼Œéƒ¨é—¨å·
select empno, ename, sal, deptno from emp;

-- å¤šè¡¨æŸ¥è¯¢
select dept.dname, emp.ename
from emp, dept
where emp.deptno = dept.deptno;

-- å­æŸ¥è¯¢ï¼ˆåªæ”¯æŒæ¯”è¾ƒç®€å•çš„å­æŸ¥è¯¢ï¼‰
-- åªæ”¯æŒfromå’Œwhereè¯­å¥ä¸­çš„å­æŸ¥è¯¢
-- æŸ¥è¯¢éƒ¨é—¨åç§°æ˜¯SALESçš„å‘˜å·¥ä¿¡æ¯
select * 
from emp 
where emp.deptno in (select deptno from dept where dname = 'SALES');

-- æ¡ä»¶å‡½æ•°
-- æŒ‰ç…§å‘˜å·¥çš„èŒä½æ¥æ¶¨å·¥èµ„ï¼šæ€»è£1000ï¼Œç»ç†800ï¼Œå…¶ä»–400
select empno, ename, job, sal,
  case job 
    when 'PREISDENT' then sal + 1000
    when 'MANAGER' then sal + 800
    else sal + 400
  end
from emp;
```

## ä½¿ç”¨sqoopå¯¼å…¥å…³ç³»å‹æ•°æ®åº“ä¸­çš„æ•°æ®

```bash
# å°†å…³ç³»å‹æ•°æ®åº“ä¸­çš„è¡¨ç»“æ„å¤åˆ¶åˆ°hiveä¸­
sqoop create-hive-table --connect jdbc://mysql://127.0.0.1:3307/test --username test --password n6zjW3zL --table t1 --hive-table t1

# ä»å…³ç³»å‹æ•°æ®åº“å¯¼å…¥æ–‡ä»¶åˆ°hiveä¸­
sqoop import --connect jdbc://mysql://127.0.0.1:3307/test --username test --password n6zjW3zL --table t2 --hive-table t2

# å°†hiveä¸­çš„è¡¨æ•°æ®å¯¼å…¥åˆ°mysqlä¸­
sqoop export --connect jdbc://mysql://127.0.0.1:3307/test --username test --password n6zjW3zL --table t3 --export-dir /user/hive/warehoser/uv/dt=2011-08-03
```

## ä½¿ç”¨JDBCè¿æ¥Hive

## Hiveçš„è‡ªå®šä¹‰å‡½æ•°

å‚è€ƒ: [03.ä½¿ç”¨hive UDFéœ€è¦çš„mavenä¾èµ–](https://blog.csdn.net/sheep8521/article/details/81001893)

### Hiveçš„è‡ªå®šä¹‰å‡½æ•°ï¼ˆUDFï¼‰ï¼šUser Defined Function

å¯ä»¥ç›´æ¥åº”ç”¨äºselectè¯­å¥ï¼Œå¯¹æŸ¥è¯¢ç»“æœåšæ ¼å¼åŒ–å¤„ç†åï¼Œå†è¾“å‡ºå†…å®¹

### Hiveè‡ªå®šä¹‰å‡½æ•°çš„å®ç°ç»†èŠ‚

* è‡ªå®šä¹‰UDFéœ€è¦ç»§æ‰¿`org.apache.hadoop.hive.sql.ql.UDF`
* éœ€è¦å®ç°`evaluate`å‡½æ•°

```sql
-- å¢åŠ è‡ªå®šä¹‰jaråŒ…
add jar /root/temp/myudf.jar;

-- åˆ›å»ºä¸´æ—¶å‡½æ•°
create temporary function myconcat as 'udf.MyConcatString';
create temporary function checksal as 'udf.CheckSalaryGrade';

-- ä½¿ç”¨
select myconcat('Hello', 'Word');
select empno, ename, sal, checksal(sal) from emp;

```













